---
title: "An Interactive webR Approach to Teaching Statistical Inference to Behavioral Science Students"
subtitle: "Null Hypothesis Significance Testing via Permutation Tests"
author: "Kimberly Henry"
format: 
  revealjs:
    theme: moon
    slide-number: true
    transition: fade
    center: true
    scrollable: true
df-print: paged
execute: 
  echo: false
  warning: false
  message: false
---

```{r}
#| message: false
#| warning: false

library(here)
library(broom)
library(tidyverse)

df <- read_csv(here("data", "uncertainty_exp2.csv")) |> 
  filter(effect_size == "Large effect size") |> 
  select(graph_type, wtp_final) |> 
  drop_na() |> 
  mutate(graph_type = factor(graph_type, 
                             levels = c("CI", "PI", "CI rescaled", "HOPS")))

```

## Why Permutation Tests?

-   **Problem**: Students struggle with NHST's abstract logic (*p*-values, sampling distributions)
-   **Solution**: Permutation tests make inference **visual** and **intuitive**

::: notes
Most students plug and chug formulas without really grasping pâ€‘values or sampling distributions. With permutation tests, they literally reshuffle the data, see the null world emerge, and ask, â€˜How unusual is our result?â€™ It turns abstract inference into a handsâ€‘on experiment.
:::

## Exploration via WebR

![](images/webr_screenshot.png){fig-align="center" width="1000"}

::: notes
I developed an interactive WebR tutorial that guides students step-by-step through the logic and implementation of permutation tests for null hypothesis significance testing.
:::

## The Study

![](images/viz_effects_title.png){fig-align="center"}

::: notes
This activity uses data from Hofman et al., shared on the Open Science Framework. The study investigates how different ways of visualizing uncertainty influence decisionâ€‘making.
:::

## The Game

![](images/blorg.png){fig-align="center" width="75%"}

::: notes
Players competed with Blorg in an iceâ€‘boulder game and could rent a special boulder for a potential edge.
:::

## Special Boulder

![](images/special_boulder.png){fig-align="center" width="75%"}

::: notes
But that boulder might help --- or it might not.
:::

## The Experimental Conditions

![](images/hulman_viz_types.png){fig-align="center" width="60%"}

$$
H_{0}: \mu_{\mathrm{CI}} - \mu_{\mathrm{CI\ rescaled}} = 0
$$

::: notes
To help players decide, they were shown one of four uncertainty visualizations. Each shows the average sliding distance for the standard and special boulders, along with uncertainty around those averages. Today, weâ€™re focusing on the Confidence Interval and Rescaled Confidence Interval conditions. Both show the same data, but the rescaled CI uses a wider yâ€‘axis, which makes the difference between the boulders look smaller. Our null hypothesis is that thereâ€™s no difference in willingness to pay between these two visualization conditions.
:::

## 1: Select & Observe

Pick two conditions & calculate **observed difference**

```{r}

# pick groups
my_groups <-
  df |>
  filter(graph_type == "CI" | graph_type == "CI rescaled") 

# calculate mean and 95% CI for each condition
df_summary <- 
  my_groups |> 
  group_by(graph_type) |>
  summarize(
    mean_wtp = mean(wtp_final),
    ci_low = mean_wtp - qt(0.975, df = n() - 1) * sd(wtp_final) / sqrt(n()),
    ci_high = mean_wtp + qt(0.975, df = n() - 1) * sd(wtp_final) / sqrt(n())
  )

# calculate the difference for annotation
observed_diff <- diff(df_summary$mean_wtp)

x_mid <- mean(c(1, 2)) # midpoint between group 1 and 2
y_mid <- mean(df_summary$mean_wtp) # midpoint between the means

# create plot
df_summary |> 
  mutate(
    group_color = case_when(
      graph_type == "CI" ~ "#f6a27b",  
      graph_type == "CI rescaled" ~ "#7bcff6",   
      TRUE ~ "#999999"                  
    )
  ) |> 
  ggplot(aes(x = graph_type, y = mean_wtp, color = group_color)) +
  # Confidence intervals
  geom_linerange(
    aes(ymin = ci_low, ymax = ci_high),
    linewidth = 2,
    alpha = 0.3
  ) +
  # Points
  geom_point(size = 4, shape = 16) +
  # Difference annotation
  geom_segment(
    x = 1, xend = 2,
    y = df_summary$mean_wtp[1], yend = df_summary$mean_wtp[2],
    color = "lightgrey", linewidth = 0.5, linetype = "dotted"
  ) +
  geom_label(
    x = x_mid, 
    y = y_mid,
    label = sprintf("Difference: %.2f", observed_diff),
    color = "black", fill = "lightgrey", size = 5
  ) +
  scale_color_identity() +  
  labs(
    title = "How Visualization Type Affects Willingness to Pay",
    subtitle = "Mean and 95% CI are displayed",
    x = "Graph type viewed / Condition", 
    y = "Willingness to pay"
  ) +
  theme_bw() +
  theme(
    plot.title       = element_text(size = 20, face = "bold"), 
    plot.subtitle    = element_text(size = 16),                  
    axis.title       = element_text(size = 14),                  
    axis.text        = element_text(size = 12),                  
    legend.text      = element_text(size = 12),                  
    legend.title     = element_text(size = 13)
  )

```

::: notes
To begin the activity, we first pick two groups and compute the observed mean difference in willingness to pay for the special boulder. This anchors students in the real effect before any shuffling happens.
:::

------------------------------------------------------------------------

## 2: Shuffle Labels to Test the Null

```{r}
#| fig.width: 12
#| fig.height: 6

set.seed(123)

n_permutations <- 5000

# create permutation data
permutation_list <- replicate(n_permutations, {
  my_groups |>
    mutate(
      original_group = graph_type,
      shuffled_group = sample(graph_type)
    ) |>
    select(wtp_final, original_group, shuffled_group)
}, simplify = FALSE)

# add observed data as permutation 0
observed_df <- my_groups |>
  mutate(
    original_group = graph_type,
    shuffled_group = graph_type,
    permutation = 0
  ) |>
  select(permutation, wtp_final, original_group, shuffled_group)

# combine observed + permuted
output <- bind_rows(
  observed_df,
  bind_rows(permutation_list, .id = "permutation") |>
    mutate(permutation = as.integer(permutation))
)

# select a subset (observed + 3 permutations)
output_subset <- output |> 
  filter(permutation %in% 0:3) 

# compute group means for crossbars
means <- output_subset |>
  group_by(permutation, shuffled_group) |>
  summarise(mean_wtp = mean(wtp_final), .groups = "drop")

# plot
ggplot(output_subset, aes(x = shuffled_group, y = wtp_final, color = original_group)) +
  geom_jitter(alpha = .5, width = 0.3, height = 0) +
  geom_crossbar(
  data = means,
  aes(x = shuffled_group, y = mean_wtp, ymin = mean_wtp, ymax = mean_wtp),
  inherit.aes = FALSE,
  width = 0.7,
  color = "black",
  linewidth = 1  
) +
  facet_wrap(nrow = 1, vars(permutation), labeller = labeller(permutation = c(
    `0` = "Observed Data",
    `1` = "Permutation 1",
    `2` = "Permutation 2",
    `3` = "Permutation 3"
  ))) +
  scale_color_manual(
    values = c(
      "CI" = "#f6a27b",
      "CI rescaled" = "#7bcff6",
      "PI" = "#999999",
      "HOPS" = "#999999"
    )
  ) +
  theme_bw() +
  labs(
    title = "Visualizing Observed and Permuted Group Assignments",
    subtitle = "First panel shows the real data; remaining panels show shuffled labels",
    caption = "Black horizontal bar shows group mean",
    x = "",
    y = "Willingness to Pay",
    color = "Original Group"
  ) +
  theme(
    plot.title       = element_text(size = 20, face = "bold"), 
    plot.subtitle    = element_text(size = 16),                  
    axis.title       = element_text(size = 14),                  
    axis.text        = element_text(size = 12),                  
    legend.text      = element_text(size = 12),                  
    legend.title     = element_text(size = 13),
    plot.caption     = element_text(size = 12),
    strip.text       = element_text(size = 12),
    legend.position  = "bottom"
  ) 

```

::: notes
Next, we randomly reassign group labels 5000 times. The first panel shows the real data; the rest show shuffled labels --- letting students watch the null world form step by step.
:::

## 3: Build the Null Distribution

```{r}

# turn list into a df
df_permutations <- permutation_list |>
  # Compute group means for each permutation
  lapply(function(df) {
    df |>
      group_by(shuffled_group) |>
      summarise(mean_under_null = mean(wtp_final), .groups = "drop")
  }) |>
  bind_rows(.id = "permutation")

# compute mean difference in each permutation
mean_diff_permutations <- 
  df_permutations |>
  pivot_wider(names_from = shuffled_group, values_from = mean_under_null) |>
  mutate(null_diff = CI - `CI rescaled`) |>
  select(permutation, null_diff)

# calculate the 2.5th and 97.5th percentiles of the 
# mean diff distribution under the null
lower_bound <- 
  mean_diff_permutations |> 
  pull(null_diff)  |> 
  quantile(0.025) 

upper_bound <- 
  mean_diff_permutations |> 
  pull(null_diff) |>
  quantile(0.975)

mean_diff_permutations |> 
  ggplot(aes(x = null_diff)) +
  geom_histogram(fill = "#ECECEC", bins = 25) +
  #geom_vline(xintercept = observed_diff, color = "#7bc043", lwd = 1) +
  # Add observed mean
  annotate("segment",
           x = observed_diff, xend = observed_diff,
           y = 400, yend = 1,
           arrow = arrow(length = unit(0.2, "cm"), type = "closed"),
           color = "#7bc043") +
  annotate("text",
           x = observed_diff, y = 500,  
           label = "Observed \ndifference (-11.75)",
           color = "#7bc043",
           fontface = "bold",
           vjust = 1.1) +
  # Add null hypothesis annotation
  annotate("segment",
           x = 0, xend = 0,
           y = 50, yend = 1,
           arrow = arrow(length = unit(0.2, "cm"), type = "closed"),
           color = "black") +
  annotate("text",
           x = 0, y = 150,  
           label = "Null hypothesis asserts\nno difference between conditions",
           color = "black",
           fontface = "bold",
           vjust = 1.1) +
  theme_bw() +
  labs(title = "Empirical Null Distribution of Condition Differences",
       y = "Number of shuffled samples",
       x = "Difference in willingness to pay between conditions") +
  theme(
    plot.title       = element_text(size = 20, face = "bold"), 
    plot.subtitle    = element_text(size = 16),                  
    axis.title       = element_text(size = 14),                  
    axis.text        = element_text(size = 12)                  
  )
  
  
```

::: notes
We shuffle, calculate the mean difference 5,000 times, and those differences form our handsâ€‘on sampling distribution under the null.
:::

## 4: Calculate Empirical p-value

What proportion of random shuffles produced effects as large as the real data?

```{r}

# tally the extreme versus not extreme permutations.
mean_diff_permutations <- 
  mean_diff_permutations  |> 
  mutate(extreme_diff = case_when(abs(null_diff) >= abs(observed_diff) ~ "extreme",
                                  TRUE ~ "not extreme")) 

mean_diff_permutations |> 
  count(extreme_diff)

# count extreme permutations (where |null_diff| â‰¥ |observed_diff|)
p_value <- mean(abs(mean_diff_permutations$null_diff) >= abs(observed_diff))

# format for reporting
cat(sprintf("p = %.3f (%.1f%% of %d permutations)", 
            p_value, 
            100*p_value, 
            nrow(mean_diff_permutations)))

```

::: notes
We simply count the proportion of shuffled differences at least as extreme as what we observed. That fraction is the pâ€‘value.

Our permutation test shows that `r sprintf("%.1f%%", 100*p_value)` of `r nrow(mean_diff_permutations)` random shuffles produced group differences as larger, or larger than, our observed difference (`r sprintf("%.2f", observed_diff)`).
:::

## 5: Compute the Standard Error

```{r}

mean_diff_permutations |> 
  ggplot(aes(x = null_diff)) +
  geom_histogram(fill = "#ECECEC", bins = 25) +
  theme_bw() +
  labs(title = "Empirical Null Distribution of Condition Differences",
       y = "Number of shuffled samples",
       x = "Difference in willingness to pay between conditions") 
  

se <- sd(mean_diff_permutations$null_diff)

cat("Standard Error (SE) (i.e., SD of null distribution):", 
    sprintf("%.3f", se), 
    "\n")

```

::: notes
The standard deviation of the null differences is our standard error --- it shows the typical variation weâ€™d expect under the null hypothesis.
:::

## 6: Construct the Test Statistic

`Group Difference/SE = Standardized Test Statistic`

```{r}

# observed t-statistic
std_test_statistic  <- observed_diff/se

# null statistics
std_mean_diff_permutations <- 
  mean_diff_permutations |> 
  mutate(std_null_diff = null_diff/se)

# get central 95% cutoffs
q_lower <- quantile(std_mean_diff_permutations$std_null_diff, 0.025)
q_upper <- quantile(std_mean_diff_permutations$std_null_diff, 0.975)

# build a density data frame
dens_obj  <- density(std_mean_diff_permutations$std_null_diff)
density_df <- data.frame(x = dens_obj$x, y = dens_obj$y)

# make the plot
ggplot(std_mean_diff_permutations, aes(x = std_null_diff)) +

  # full density
  geom_density(fill = "#ECECEC", alpha = 0.5) +

  # shaded middle 95%
  geom_area(
    data = density_df |> filter(x >= q_lower, x <= q_upper),
    aes(x = x, y = y),
    fill = "#D4D4D4",
    alpha = 0.6
  ) +

  # annotation text
  annotate(
    "text",
    x = 0,
    y = max(density_df$y) * 0.125,
    label = paste0("If Hâ‚€ is true,\n",
                   "â‰ˆ95% of all standardized test statistics\n",
                   "will fall in this region"),
    family    = "sans",
    size      = 4,
    lineheight= 0.9,
    hjust     = 0.5
  ) +

  # arrow to observed t
  annotate(
    "segment",
    x = std_test_statistic,
    xend = std_test_statistic,
    y = max(density_df$y) * 0.5,
    yend = 0,
    arrow = arrow(length = unit(0.2, "cm"), type = "closed"),
    color = "#7bc043"
  ) +

  # observed t label
  annotate(
    "text",
    x = std_test_statistic,
    y = max(density_df$y) * 0.6,
    label = "Observed standardized \ntest statistic \n -11.75/5.79 = -2.03",
    fontface = "bold",
    family = "sans",
    color = "#7bc043",
    size = 4
  ) +

  labs(
    title = "Empirical Null Distribution of Condition Differences (Standardized)",
    x     = "Standardized null test statistic (difference between conditions/SE)",
    y     = "Density"
  ) +

  theme_bw()

```

::: notes
We standardize the observed difference using the SE, then plot it on the null curve so students can see how far out it lands.
:::

------------------------------------------------------------------------

## 7: Compare to a Parametric Approach

```{r}
#| echo: true

my_groups |> 
  infer::t_test(wtp_final ~ graph_type, 
         var.equal = TRUE,
         order = c("CI rescaled", "CI"),
         alternative = "two-sided") |> 
  select(estimate, statistic, p_value )

```

::: notes
Finally, we run a classic tâ€‘test and compare. This sideâ€‘byâ€‘side helps students appreciate when permutation and parametric approaches agree --- or why they might differ.
:::

## Instructor Benefits

-   **Zero setup**: Runs in-browser (webR)
-   **Reusable**: GitHub repo for easy adoption
-   **Flexible**: Adaptable to other datasets

ðŸ”— **Links**: [https://KimberlyHenry.github.io/UseR2025/](https://kimberlyhenry.github.io/UseR2025/){.uri}

::: notes
WebR runs in the browser --- no installs are necessary. Everything for the activity is on GitHub, ready to use or adapt.
:::
